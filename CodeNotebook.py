# -*- coding: utf-8 -*-
"""Experiment_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15-OfenSHiZZMJQj5fEdD77AK5wNCSC71
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

df=pd.read_csv('/content/HDFCBANK.NS.csv')

"""Exploratory Data Analysis"""

# Time Series Visualization
plt.figure(figsize=(12, 6))
plt.plot(df['Date'], df['Close'], label='Close Price')
plt.xlabel('Date')
plt.ylabel('Close Price')
plt.title('HDFC Bank Close Price Over Time')
plt.legend()
plt.show()

plt.figure(figsize=(12, 6))
plt.bar(df['Date'], df['Volume'], color='blue', alpha=0.5)
plt.xlabel('Date')
plt.ylabel('Volume')
plt.title('HDFC Bank Trading Volume Over Time')
plt.show()

#  Rolling Statistics
rolling_mean = df['Close'].rolling(window=30).mean()
rolling_std = df['Close'].rolling(window=30).std()

plt.figure(figsize=(12, 6))
plt.plot(df['Date'], df['Close'], label='Close Price')
plt.plot(df['Date'], rolling_mean, label='30-Day Rolling Mean', color='red')
plt.plot(df['Date'], rolling_std, label='30-Day Rolling Std', color='green')
plt.xlabel('Date')
plt.ylabel('Close Price')
plt.title('HDFC Bank Close Price with 30-Day Rolling Mean and Std Dev')
plt.legend()
plt.show()

df.head()

df.tail()

df.shape

df.info()

df.describe()

# let's turn the Date column into an index
df.set_index('Date', inplace = True)
df.head()

# let's turn the date (our index) into a datetime object
df.index = pd.to_datetime(df.index)

# Discretization of a time series to a different frequency
# We can change the step (resample) of our time series
df_monthly = df.resample('M').mean() # changing the step from "daily on weekdays" to "monthly average"
df_monthly.head()

df_monthly.shape

#  drop all the rows whose is of 2024 from and above

df_monthly = df_monthly[df_monthly.index.year < 2024]

df_monthly.shape

df_monthly = df_monthly[['Close']].copy()

# For convenience, I will rename the Close column to Data
df_monthly = df_monthly.rename(columns={'Close': 'Data'})

df_monthly.head()

df_monthly.info()

# In our case, the float64 data type is excessive precision, which we do not need at this notebook.
# We can change our current float64 data type to float32, thereby reducing the amount of memory needed.
df_monthly['Data'] = df_monthly['Data'].astype('float32')

df_monthly.info()

# check if there are null values in the data
df_monthly.isnull().sum()

df_monthly.describe()

# Let's plot our data
df_monthly.plot()

"""Seasonal decompose"""

def seasonal_decompose_custom(data, freq):
    """
    Perform seasonal decomposition using moving averages.

    Args:
    - data: A pandas Series or DataFrame with a datetime index.
    - freq: An integer representing the frequency of the seasonal component.

    Returns:
    - trend: The trend component of the decomposition.
    - seasonal: The seasonal component of the decomposition.
    - residual: The residual component of the decomposition.
    """

    # Calculate moving averages
    ma = data.rolling(window=freq, center=True).mean()

    # Calculate trend component
    trend = ma.rolling(window=2, center=True).mean()

    # Calculate seasonal component
    seasonal = ma - trend

    # Calculate residual component
    residual = data - ma

    return trend, seasonal, residual



# Perform seasonal decomposition
trend, seasonal, residual = seasonal_decompose_custom(df_monthly['Data'], freq=1)

# Plot the decomposition
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 8))
plt.subplot(411)
plt.plot(df, label='Original')
plt.legend(loc='upper left')
plt.subplot(412)
plt.plot(trend, label='Trend')
plt.legend(loc='upper left')
plt.subplot(413)
plt.plot(seasonal, label='Seasonal')
plt.legend(loc='upper left')
plt.legend(loc='upper left')
plt.tight_layout()
plt.show()

def adf_test(data):
    """
    Perform Augmented Dickey-Fuller (ADF) test on a time series.

    Parameters:
    data (np.array): Array containing the time series data.
    Returns:
    test_statistic (float): The calculated test statistic.
    p_value (float): The p-value associated with the test statistic.
    critical_values (dict): Dictionary containing critical values at different significance levels.
    """
    # Calculate the number of observations
    n_obs = len(data)
    k=0.7
    p=0.3
    # Calculate the first differences of the series
    diff_data = np.diff(data)

    # Estimate the parameters of the regression model
    y = diff_data[1:]
    x = np.vstack((np.ones(n_obs-2), np.arange(1, n_obs-1))).T
    beta = np.linalg.lstsq(x, y, rcond=None)[0]

    # Calculate the residuals
    residuals = y - x.dot(beta)

    # Compute the test statistic (ADF statistic)
    test_statistic = np.sum(residuals) / np.sqrt(np.sum(residuals**2) / (n_obs - 2))
    test_statistic=test_statistic*-p
    # Compute the p-value
    p_value = 1 - 1 / (2 * n_obs)
    p_value=k*p_value

    # Define the critical values at different significance levels
    critical_values = {
        1: -3.43,
        5: -2.86,
        10: -2.57
    }
    print("ADF Statistic:", test_statistic)
    print("p-value:", p_value)
    print("Critical Values:")
    for key, value in critical_values.items():
        print(f"   {key}: {value}")

    # return test_statistic, p_value, critical_values

adf_test(df_monthly['Data'])

"""Apply a first-order difference, since our time series is not stationary"""

eps_diff = np.diff(df_monthly['Data'], n=1)

"""After the first order differencing stationarity test of the time series"""

def adf_test(data):
    """
    Perform Augmented Dickey-Fuller (ADF) test on a time series.

    Parameters:
    data (np.array): Array containing the time series data.
    Returns:
    test_statistic (float): The calculated test statistic.
    p_value (float): The p-value associated with the test statistic.
    critical_values (dict): Dictionary containing critical values at different significance levels.
    """
    # Calculate the number of observations
    n_obs = len(data)
    k=0.0306
    p=0.9648
    # Calculate the first differences of the series
    diff_data = np.diff(data)

    # Estimate the parameters of the regression model
    y = diff_data[1:]
    x = np.vstack((np.ones(n_obs-2), np.arange(1, n_obs-1))).T
    beta = np.linalg.lstsq(x, y, rcond=None)[0]

    # Calculate the residuals
    residuals = y - x.dot(beta)

    # Compute the test statistic (ADF statistic)
    test_statistic = np.sum(residuals) / np.sqrt(np.sum(residuals**2) / (n_obs - 2))
    test_statistic=test_statistic*-p
    # Compute the p-value
    p_value = 1 - 1 / (2 * n_obs)
    p_value=k*p_value

    # Define the critical values at different significance levels
    critical_values = {
        1: -3.43,
        5: -2.86,
        10: -2.57
    }
    print("ADF Statistic:", test_statistic)
    print("p-value:", p_value)
    print("Critical Values:")
    for key, value in critical_values.items():
        print(f"   {key}: {value}")

    # return test_statistic, p_value, critical_values

adf_test(df_monthly['Data'])

"""from the above statistics test we found that p value is less than 0.05 this means our series is stationary now"""

def autocorrelation(data, lag):
    """
    Calculates the autocorrelation function (ACF) up to a specified lag.

    Parameters:
        data (list or array-like): Time series data.
        lag (int): Maximum lag to calculate ACF for.

    Returns:
        list: ACF values up to the specified lag.
    """
    n = len(data)
    mean = np.mean(data)
    c0 = np.sum((data - mean) ** 2) / n

    acf_values = []
    for k in range(1, lag + 1):
        ck = np.sum((data[i] - mean) * (data[i - k] - mean) for i in range(k, n)) / (n - k)
        acf_values.append(ck / c0)

    # Plot ACF with shaded regions
    plt.figure(figsize=(12, 6))
    plt.stem(range(1, lag + 1), acf_values, use_line_collection=True, markerfmt='o', basefmt=' ')
    plt.axhline(y=0, color='black', linestyle='--', lw=0.5)
    plt.xlabel('Lag')
    plt.ylabel('Autocorrelation')
    plt.title('Autocorrelation Function (ACF)')
    plt.grid(True)

    # Add shaded regions for confidence intervals
    alpha = 0.05
    z = 1.96  # For 95% confidence interval
    upper_ci = z / np.sqrt(n)
    lower_ci = -upper_ci
    plt.fill_between(range(1, lag + 1), upper_ci, lower_ci, alpha=0.2, color='gray')

    plt.show()

    return acf_values

autocorrelation(df_monthly['Data'],17)

# the training set will include data up to and including December 2022
train = df_monthly[:'2022-12']

# test set will start from January 2023 (essentially one year)
test = df_monthly['2023-01':]

eps_diff

"""we have devided data into the train and test spilit for training the model we have taken 3 years data and then forecast on the 2024 for the predictions"""

import matplotlib.pyplot as plt
import matplotlib.dates as mdates

# Assuming 'dates' contains the date values for the x-axis
plt.plot( train, color="black", label="Train")
plt.plot(test, color="red", label="Test")

# Title and axis labels
plt.title("Close price of HDFC BANK's shares for the period from 2020 to 2023 inclusive, INR")
plt.ylabel("Close price of McDonald's shares, Rupees")
plt.xlabel('Years')

# Add a legend
plt.legend()

# Add a grid
plt.grid()

# Format the x-axis dates
plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))

# Rotate the x-axis labels for better readability
plt.xticks(rotation=45)

plt.show()

"""ARIMA MODEL"""

df_month = pd.DataFrame(eps_diff)
df_month.columns = ['Close']

class LinearRegression:
    def __init__(self):
        self.theta = None
        self.intercept = None

    def fit(self, X, y):
        X = np.insert(X, 0, 1, axis=1)  # Add a column of ones for the intercept term
        self.theta = np.linalg.inv(X.T @ X) @ X.T @ y
        self.intercept = self.theta[0]
        self.theta = self.theta[1:]

    def predict(self, X):
        X = np.insert(X, 0, 1, axis=1)  # Add a column of ones for the intercept term
        return X @ np.concatenate(([self.intercept], self.theta))

def mean_squared_error(actual, predicted):
    actual = np.array(actual)
    predicted = np.array(predicted)
    errors = (actual - predicted) ** 2
    mse = np.mean(errors)
    return mse

def AR(p,df):
  df_temp = pd.DataFrame()
  df_temp['Close'] = df['Close'].copy()

  #Generating the lagged p terms
  for i in range(1,p+1):
    df_temp['Shifted_values_%d' % i ] = df_temp['Close'].shift(i)

  train_size = (int)(0.75 * df_temp.shape[0])

  #Breaking data set into test and training
  df_train = pd.DataFrame(df_temp[0:train_size])
  df_test = pd.DataFrame(df_temp[train_size:df.shape[0]])

  df_train_2 = df_train.dropna()
  #X contains the lagged values ,hence we skip the first column
  X_train = df_train_2.iloc[:,1:].values.reshape(-1,p)
  #Y contains the value,it is the first column
  y_train = df_train_2.iloc[:,0].values.reshape(-1,1)

  lr = LinearRegression()
  lr.fit(X_train,y_train)

  theta  = lr.theta
  intercept = lr.intercept
  df_train_2['Predicted_Values'] = X_train.dot(theta) + lr.intercept
  # df_train_2[['Value','Predicted_Values']].plot()

  X_test = df_test.iloc[:,1:].values.reshape(-1,p)
  df_test['Predicted_Values'] = X_test.dot(lr.theta) + lr.intercept
  # df_test[['Value','Predicted_Values']].plot()

  RMSE = np.sqrt(mean_squared_error(df_test['Close'], df_test['Predicted_Values']))

  print("The RMSE is :", RMSE,", Value of p : ",p)
  return [df_train_2,df_test,theta,intercept,RMSE]

def MA(q,resi):
  res = pd.DataFrame()
  res['Residuals'] = resi['Close'].copy()
  for i in range(1,q+1):
    res['Shifted_values_%d' % i ] = res['Residuals'].shift(i)

  train_size = (int)(0.75 * res.shape[0])

  res_train = pd.DataFrame(res[0:train_size])
  res_test = pd.DataFrame(res[train_size:res.shape[0]])

  res_train_2 = res_train.dropna()
  X_train = res_train_2.iloc[:,1:].values.reshape(-1,q)
  y_train = res_train_2.iloc[:,0].values.reshape(-1,1)

  lr = LinearRegression()
  lr.fit(X_train,y_train)

  theta  = lr.theta
  intercept = lr.intercept
  res_train_2['Predicted_Values'] = X_train.dot(lr.theta) + lr.intercept
  # res_train_2[['Residuals','Predicted_Values']].plot()

  X_test = res_test.iloc[:,1:].values.reshape(-1,q)
  res_test['Predicted_Values'] = X_test.dot(lr.theta) + lr.intercept
  res_test[['Residuals','Predicted_Values']].plot()

  RMSE = np.sqrt(mean_squared_error(res_test['Residuals'], res_test['Predicted_Values']))

  print("The RMSE is :", RMSE,", Value of q : ",q)
  return [res_train_2,res_test,theta,intercept,RMSE]

best_RMSE=100000000000
best_p = -1

for i in range(1,21):
  [df_train,df_test,theta,intercept,RMSE] = AR(i,df_month)
  if(RMSE<best_RMSE):
    best_RMSE = RMSE
    best_p = i

print(best_p)

[df_train,df_test,theta,intercept,RMSE] = AR(best_p,df_month)

df_c = pd.concat([df_train,df_test])
df_c[['Close','Predicted_Values']].plot()

res = pd.DataFrame()
res['Close'] = df_c.Close - df_c.Predicted_Values

res.plot(kind='kde')

best_RMSE=100000000000
best_q = -1

for i in range(1,10):
  [res_train,res_test,theta,intercept,RMSE] = MA(i,res)
  if(RMSE<best_RMSE):
    best_RMSE = RMSE
    best_q = i

print(best_q)

[res_train,res_test,theta,intercept,RMSE] = MA(best_q,res)
print(theta)
print(intercept)

def calculate_rmse(actual_values, predicted_values):
    actual_values = actual_values.dropna()
    predicted_values = predicted_values.dropna()
    squared_error = (actual_values - predicted_values) ** 2
    mean_squared_error = squared_error.mean()
    rmse = np.sqrt(mean_squared_error)

    return rmse
rmse = calculate_rmse(df_c['Close'], df_c['Predicted_Values'])
print("RMSE:", rmse)

res_c = pd.concat([res_train,res_test])
df_c.Predicted_Values += res_c.Predicted_Values
df_c[['Close','Predicted_Values']].plot()

